worker_processes auto;
pid /var/run/nginx.pid;

## Rough sizing
# CPU- 1 core per 1-2 Gpbs of non SSL traffic
# For ssl connections divide by 5 if ssls are terminated on this. 
# 1 mb for every keepalve connection
# add 8mb ram for core. 

# suggest run this in a docker orchestrator with auto scale.


events {
    worker_connections 4096;
}



http {

upstream origin {
    server 192.168.43.206:80;
    #server 10.0.0.2:11211; #Add new servers here
    keepalive 32; #tune this and keep it high enough so that new TCP and TLS nego does not need to happen. 
}

log_format  main  'Remote IP: $remote_addr - [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"'
                      '$request_time $upstream_response_time $pipe';

    keepalive_timeout 60s;
    sendfile on;

    limit_req_zone $remote_addr zone=api:20m rate=60r/m; # keep the rate high enough for the server to handle the backend traffic
    limit_req_status 429;
    limit_req_log_level notice;

    server {
	    listen       81;
    	    server_name  default;

            limit_req zone=api burst=10 delay=5;

    	    access_log  /var/log/nginx/access.log  main;

   	 location / {
        	proxy_pass http://origin;
                proxy_http_version 1.1;
        	proxy_set_header Connection "";
    	}
    }
}

